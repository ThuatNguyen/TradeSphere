"""AI service for chatbot and scam analysis"""
from openai import AsyncOpenAI
from typing import List, Dict, Optional
import json
from ..config import settings


# AI Prompts
ANTI_SCAM_SYSTEM_PROMPT = """
Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn vá» phÃ²ng chá»‘ng lá»«a Ä‘áº£o táº¡i Viá»‡t Nam.

Nhiá»‡m vá»¥ cá»§a báº¡n:
- TÆ° váº¥n cÃ¡ch nháº­n biáº¿t cÃ¡c chiÃªu thá»©c lá»«a Ä‘áº£o phá»• biáº¿n
- PhÃ¢n tÃ­ch thÃ´ng tin nghi ngá» (sá»‘ Ä‘iá»‡n thoáº¡i, tin nháº¯n, email)
- ÄÆ°a ra cáº£nh bÃ¡o vÃ  khuyáº¿n nghá»‹ cá»¥ thá»ƒ
- HÆ°á»›ng dáº«n cÃ¡ch bÃ¡o cÃ¡o vÃ  xá»­ lÃ½ khi gáº·p lá»«a Ä‘áº£o

Phong cÃ¡ch giao tiáº¿p:
- ThÃ¢n thiá»‡n, dá»… hiá»ƒu, khÃ´ng dÃ¹ng thuáº­t ngá»¯ phá»©c táº¡p
- Cá»¥ thá»ƒ, cÃ³ vÃ­ dá»¥ minh há»a
- LuÃ´n khuyáº¿n khÃ­ch ngÆ°á»i dÃ¹ng cáº£nh giÃ¡c
- Tráº£ lá»i ngáº¯n gá»n, sÃºc tÃ­ch (3-5 cÃ¢u)

LÆ°u Ã½:
- KHÃ”NG Ä‘Æ°a ra lá»i khuyÃªn phÃ¡p lÃ½ chÃ­nh thá»©c
- KHÃ”NG kháº³ng Ä‘á»‹nh 100% ai Ä‘Ã³ lÃ  lá»«a Ä‘áº£o náº¿u chÆ°a cÃ³ báº±ng chá»©ng rÃµ rÃ ng
- LUÃ”N khuyÃªn ngÆ°á»i dÃ¹ng kiá»ƒm chá»©ng ká»¹ vÃ  bÃ¡o cÆ¡ quan chá»©c nÄƒng
"""

ANALYZE_SCAM_PROMPT_TEMPLATE = """
PhÃ¢n tÃ­ch Ä‘oáº¡n vÄƒn báº£n sau Ä‘á»ƒ xÃ¡c Ä‘á»‹nh kháº£ nÄƒng lá»«a Ä‘áº£o:

VÄƒn báº£n: {text}

CÃ¡c dáº¥u hiá»‡u lá»«a Ä‘áº£o thÆ°á»ng gáº·p:
- YÃªu cáº§u chuyá»ƒn tiá»n gáº¥p, kháº©n cáº¥p
- Máº¡o danh cÆ¡ quan chá»©c nÄƒng, ngÃ¢n hÃ ng
- Há»©a háº¹n lá»£i nhuáº­n cao, nhanh chÃ³ng, khÃ´ng rá»§i ro
- Äe dá»a, gÃ¢y Ã¡p lá»±c tÃ¢m lÃ½
- Lá»—i chÃ­nh táº£, ngá»¯ phÃ¡p
- Link rÃºt gá»n hoáº·c link láº¡
- YÃªu cáº§u thÃ´ng tin cÃ¡ nhÃ¢n nháº¡y cáº£m

Tráº£ vá» JSON vá»›i format:
{{
  "is_scam": true/false,
  "confidence": 0-100,
  "indicators": ["dáº¥u hiá»‡u 1", "dáº¥u hiá»‡u 2", ...],
  "explanation": "Giáº£i thÃ­ch chi tiáº¿t ngáº¯n gá»n"
}}
"""


class AIService:
    """OpenAI-based AI service"""
    
    def __init__(self):
        self.client: Optional[AsyncOpenAI] = None
        if settings.OPENAI_API_KEY:
            self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
    
    async def chat(
        self, 
        message: str, 
        context: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """Chat with AI"""
        if not self.client:
            error_msg = "AI service chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh. Vui lÃ²ng thÃªm OPENAI_API_KEY."
            print(f"âŒ {error_msg}")
            return error_msg
        
        print(f"ğŸ¤– AI chat called with model: {settings.AI_MODEL}")
        print(f"ğŸ“ Message: {message[:100]}...")
        
        try:
            messages = [
                {"role": "system", "content": ANTI_SCAM_SYSTEM_PROMPT}
            ]
            
            # Add context (previous messages)
            if context:
                messages.extend(context[-5:])  # Last 5 messages only
            
            messages.append({"role": "user", "content": message})
            
            response = await self.client.chat.completions.create(
                model=settings.AI_MODEL,
                messages=messages,
                temperature=settings.AI_TEMPERATURE,
                max_tokens=settings.AI_MAX_TOKENS,
            )
            
            ai_response = response.choices[0].message.content
            print(f"âœ… AI responded: {ai_response[:100]}...")
            return ai_response
            
        except Exception as e:
            error_msg = f"Lá»—i AI service: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    async def analyze_scam_text(self, text: str) -> Dict:
        """Analyze text for scam indicators"""
        if not self.client:
            return {
                "is_scam": False,
                "confidence": 0,
                "indicators": [],
                "explanation": "AI service chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh"
            }
        
        try:
            prompt = ANALYZE_SCAM_PROMPT_TEMPLATE.format(text=text)
            
            response = await self.client.chat.completions.create(
                model=settings.AI_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,  # Lower temperature for more consistent analysis
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result
            
        except Exception as e:
            return {
                "is_scam": False,
                "confidence": 0,
                "indicators": [],
                "explanation": f"Lá»—i phÃ¢n tÃ­ch: {str(e)}"
            }
    
    async def generate_scam_report_summary(self, phone: str, name: str, amount: int) -> str:
        """Generate natural language summary for scam report"""
        if not self.client:
            return f"Cáº£nh bÃ¡o: {name} ({phone}) - Sá»‘ tiá»n: {amount:,} VNÄ"
        
        try:
            prompt = f"""
            Viáº¿t má»™t cáº£nh bÃ¡o ngáº¯n gá»n (1-2 cÃ¢u) vá» vá»¥ lá»«a Ä‘áº£o:
            - TÃªn: {name}
            - Sá»‘ Ä‘iá»‡n thoáº¡i: {phone}
            - Sá»‘ tiá»n: {amount:,} VNÄ
            
            Giá»ng Ä‘iá»‡u: Cáº£nh bÃ¡o nhÆ°ng khÃ´ng phÃ¡n xÃ©t.
            """
            
            response = await self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=100,
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"âš ï¸ Cáº£nh bÃ¡o: {name} ({phone}) liÃªn quan Ä‘áº¿n giao dá»‹ch nghi ngá» sá»‘ tiá»n {amount:,} VNÄ"


# Singleton instance
ai_service = AIService()
